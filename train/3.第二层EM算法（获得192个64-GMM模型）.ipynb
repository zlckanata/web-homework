{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#引包，dct特征用opencv中的方法来提取。\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取每张图片的GMM-8\n",
    "ueas = np.load('ueas.npz')\n",
    "Us = ueas['U']\n",
    "Es = ueas['E']\n",
    "As = ueas['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#各类图像的GMM整合（第二层GMM）\n",
    "def gaussion_prob(data_U,U,E,th=5e-4):#多数据多高斯同时求概率\n",
    "    #input_dim:  data_U-(N,dim)  U-(m,dim)  E-(m,dim,dim)\n",
    "    #output_dim:  prob-(m,N)\n",
    "    N,dim = data_U.shape\n",
    "    m = U.shape[0]\n",
    "    E_d = np.eye(dim)*th\n",
    "    prob = np.zeros((m,N))\n",
    "    inv_Es = np.zeros((m,dim,dim))\n",
    "    for i in range(m):\n",
    "        det_E = np.linalg.det(E[i]+E_d)\n",
    "        inv_E = np.linalg.inv(E[i]+E_d)\n",
    "        inv_Es[i] = inv_E\n",
    "        xishu = 1 / (det_E ** 0.5 * (2.0 * np.pi) ** (dim/2))\n",
    "        X_U = data_U - U[i]\n",
    "        zhishu = np.sum(np.dot(X_U,inv_E) * X_U,axis=1) *(-0.5)\n",
    "        prob[i] = xishu * np.exp(zhishu)\n",
    "    return prob,inv_Es\n",
    "\n",
    "def trace(data_E,iE):\n",
    "    #input_dim:  data_E-(N,dim,dim)  iE-(m,dim,dim)\n",
    "    #output_dim: exp_tr-(m,N)\n",
    "    N,dim,_ = data_E.shape\n",
    "    m = iE.shape[0]\n",
    "    tr = np.zeros((m,N))\n",
    "    for i in range(dim):\n",
    "        tr += np.dot(iE[:,i,:],data_E[:,:,i].T)#存疑\n",
    "    exp_tr = np.exp(-0.5*tr)\n",
    "    return exp_tr\n",
    "\n",
    "def H(data_PI,PI,prob,trace):\n",
    "    #input_dim:  data_PI-(N,)  PI-(m,)  prob-(m,N)  trace(m,N)\n",
    "    #output_dim:  h-(m,N)\n",
    "    mul = prob * trace\n",
    "    up = np.power(mul,data_PI) * PI[:,np.newaxis]\n",
    "    down = np.sum(up,axis=0)\n",
    "    h = up/down\n",
    "    return h\n",
    "\n",
    "def check_diff(x,y,ma,me):\n",
    "    check_max = np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "    check_mean = np.mean(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "    #print 'max',check_max,'\\nmean',check_mean\n",
    "    if check_max < ma and check_mean < me:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def GMM2(data_U,data_E,data_PI,m):\n",
    "    #初始化\n",
    "    N,dim = data_U.shape\n",
    "    randlist = np.random.choice(N, m, replace=False)\n",
    "    U = np.copy(data_U[randlist])\n",
    "    E = np.copy(data_E[randlist])\n",
    "    PI = np.copy(data_PI[randlist])\n",
    "    oldU = np.copy(U)\n",
    "    \n",
    "    while True:\n",
    "        #（E步）\n",
    "        prob,iE = gaussion_prob(data_U,U,E,5e-4)\n",
    "        tra = trace(data_E,iE)\n",
    "        h = H(data_PI,PI,prob,tra)\n",
    "        #（M步）\n",
    "        PI = np.sum(h,axis=1) / N\n",
    "        pre_w = np.nan_to_num(h * data_PI)\n",
    "        w = pre_w/np.sum(pre_w,axis=1,keepdims=True)\n",
    "        U = np.dot(w,data_U)\n",
    "        for i in range(m):\n",
    "            t = data_U - U[i]\n",
    "            E1 = np.sum(w[i,:,np.newaxis,np.newaxis] * data_E,axis=0)\n",
    "            E2 = np.dot(t.T*w[i],t)\n",
    "            E[i] = E1 + E2\n",
    "        \n",
    "        #收敛判断\n",
    "        U = np.nan_to_num(U)\n",
    "        E = np.nan_to_num(E)\n",
    "        PI = np.nan_to_num(PI)\n",
    "        if check_diff(U,oldU,1,0.01):\n",
    "            break;\n",
    "        oldU = np.copy(U)\n",
    "        \n",
    "    return (U,E,PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对标签进行选取，只要出现10次以上的（共有192个），用label_sets来保存各个标签的图片编号，并保存每个标签出现的次数。\n",
    "train_label = np.loadtxt('train.csv',delimiter=',')\n",
    "train_label_count = train_label.sum(0)\n",
    "label_index = np.arange(260)[train_label_count > 10]\n",
    "train_label_samp = train_label[:,label_index]\n",
    "label_sets = []\n",
    "for i in range(train_label_samp.shape[1]):\n",
    "    label_sets.append(np.arange(4500)[train_label_samp[:,i] == 1])\n",
    "np.save('label_times',train_label_count[label_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#生成最终的模型\n",
    "models = []\n",
    "tic = time.time()\n",
    "for i in range(len(label_sets)):\n",
    "    U = np.nan_to_num(Us[label_sets[i]].reshape(8*label_sets[i].shape[0],63))\n",
    "    E = np.nan_to_num(Es[label_sets[i]].reshape(8*label_sets[i].shape[0],63,63))\n",
    "    A = np.nan_to_num(As[label_sets[i]].reshape(8*label_sets[i].shape[0]))\n",
    "    models.append(GMM2(U,E,A,64))\n",
    "    print i,':',time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#保存最终模型\n",
    "def model_change_dump(model_to_change,dump_name):\n",
    "    n = len(model_to_change)\n",
    "    U_dump = np.zeros((n,64,63))\n",
    "    E_dump = np.zeros((n,64,63,63))\n",
    "    A_dump = np.zeros((n,64))\n",
    "    for i in range(n):\n",
    "        U_dump[i] = model_to_change[i][0]\n",
    "        E_dump[i] = model_to_change[i][1]\n",
    "        A_dump[i] = model_to_change[i][2]\n",
    "    np.savez_compressed(dump_name,U=U_dump,E=E_dump,A=A_dump)\n",
    "model_change_dump(models3,'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#载入标签字符对应词典,截取词典的一部分,保存为新的词典\n",
    "cor_dict = np.loadtxt('corel5k_words.txt',dtype=np.str)\n",
    "cor_dict_samp = cor_dict[label_index]\n",
    "np.savetxt('new_words.txt',cor_dict_samp,fmt='%s',delimiter='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
